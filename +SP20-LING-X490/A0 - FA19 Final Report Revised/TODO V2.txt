1-28-2020
TODO:
- Work on dev, find best setting, then run on test
- Do everything on dev at first, last thing: run on test
- toxicitiy (target) is 'y'
- third column is what you're working on: the 'x'
	- remove quotes
	- run CV on entire "notes" column
- don't use accuracy, use macro avg, f (harmonic mean)

****
baseline (HW for next time):
- col 2: y, leave y as is, col 3: x
- x: CV
- 5-fold
	- Way too long? Split into 80% train, rest dev, testing on latter
	- if there's time, do parameter optimization (GridSearchCV)

filter:
- different methods of getting data
	- Kaggle, Kumar: boosting abusive language
	- Other: topic sampling

- On Kaggle: do boosted sampling (there already)
	- HW: read and understand boosting

- focus on English-language tweets

- filter on events; sift through (topic filtering). Islam?
	- manually create list of islam-related hashtags, don't have to be abusive. want to focus on non-abusive.
	- see how large you can get the topic-filtered set, trim down to same size as other

- one method might work better than the other due to overt abusive language
	- easy for machine learner to detect
	- covert hard to detect w/ bag of words. e.g. "Keep Hillary out of the White House"

- Can an Islam model detect abusive language in Australian Cooking Show set?
- suspiscion: more overtly abusive with filtering

- the more explicit abuse -> the easier the task
- Wiegand talks about this across different datasets. We want to do this on one dataset (Kaggle)


Code:
- DF dimensions

Paper:
- 2: Sampling theory
- 2: Condition corresponding to sampling used in other datasets
	- i.e. find hashtags in data (e.g. football), sample based off that
- 2.1.1: describe 7 columns of numerical data
- 2.1.2: Boosted sampling method
- 2.1.2: Random sampling method